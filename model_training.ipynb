{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown\n",
    "from typing import List\n",
    "import cv2\n",
    "import dlib\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers, Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "def load_video(path: str) -> List[float]: \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for i in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if i == 0:\n",
    "            face_box = detector(frame)[0]\n",
    "            landmarks = predictor(frame, face_box)\n",
    "            xsum, ysum = 0, 0\n",
    "            for j in range(48, 68):\n",
    "                x, y = landmarks.part(j).x, landmarks.part(j).y\n",
    "                xsum += x\n",
    "                ysum += y\n",
    "                \n",
    "            xc, yc = round(xsum / 20), round(ysum / 20)\n",
    "            x1, x2 = xc - 50, xc + 50\n",
    "            y1, y2 = yc - 25, yc + 25\n",
    "             \n",
    "        frames.append(frame[y1:y2, x1:x2])\n",
    "    cap.release()\n",
    "    frames = tf.expand_dims(frames, -1)\n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([75, 50, 100, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = load_video(\"./data/s1/bbaf2n.mpg\")\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f53f781fc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(video[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transcript(file_path: str) -> str:\n",
    "    words = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            word = line.split()[2]\n",
    "            if word != \"sil\":\n",
    "                words.append(word)\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "transcripts_path = \"./data/alignments/s1/\"\n",
    "\n",
    "for transcript in os.listdir(transcripts_path):\n",
    "    transcript_path = os.path.join(transcripts_path, transcript)\n",
    "    vocab.update(get_transcript(transcript_path))\n",
    "vocab = sorted(list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_to_num = layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokens(file_path: str) -> str:\n",
    "    transcript = get_transcript(file_path)\n",
    "    return char_to_num(list(transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(sample_name):\n",
    "    sample_name = sample_name.numpy().decode(\"utf-8\")\n",
    "    sample_name = sample_name.split(\"\\\\\")[-1]\n",
    "    sample_name = sample_name.removesuffix(\".mpg\")\n",
    "    sample_name = sample_name.removesuffix(\".align\")\n",
    "    transcript_path = os.path.join(\"./data/alignments/s1\", sample_name + \".align\")\n",
    "    video_path = os.path.join(\"./data/s1\", sample_name + \".mpg\")\n",
    "    \n",
    "    video = load_video(video_path)\n",
    "    tokens = load_tokens(transcript_path)\n",
    "    return video, tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappable_function(path:str) -> List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.list_files(\"./data/s1/*.mpg\")\n",
    "dataset = dataset.shuffle(10)\n",
    "dataset = dataset.map(mappable_function)\n",
    "dataset = dataset.padded_batch(4, padded_shapes=([75, None, None, None], [40]))\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = dataset.take(int(len(dataset) * 0.8))\n",
    "test_dataset = dataset.skip(int(len(dataset) * 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lip_net():\n",
    "    inputs = layers.Input([75, 50, 100, 1])\n",
    "    \n",
    "    conv1 = layers.Conv2D(128, 3, padding=\"same\")(inputs)\n",
    "    relu1 = layers.Activation(\"relu\")(conv1)\n",
    "    pool1 = layers.MaxPool3D((1, 2, 2))(relu1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(256, 3, padding=\"same\")(pool1)\n",
    "    relu2 = layers.Activation(\"relu\")(conv2)\n",
    "    pool2 = layers.MaxPool3D((1, 2, 2))(relu2)\n",
    "    \n",
    "    conv3 = layers.Conv2D(75, 3, padding=\"same\")(pool2)\n",
    "    relu3 = layers.Activation(\"relu\")(conv3)\n",
    "    pool3 = layers.MaxPool3D((1, 2, 2))(relu3)\n",
    "    \n",
    "    flat = layers.TimeDistributed(layers.Flatten())(pool3)\n",
    "    \n",
    "    lstm1 = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(flat)\n",
    "    lstm2 = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(lstm1)\n",
    "    \n",
    "    outputs = layers.Dense(char_to_num.vocabulary_size() + 1, activation=\"softmax\")(lstm2)\n",
    "    \n",
    "    return Model(inputs=[inputs], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip_net = get_lip_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 75, 50, 100, 1)   0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 75, 50, 100, 128   1280      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 75, 50, 100, 128   0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3  (None, 75, 25, 50, 128)   0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 25, 50, 256)   295168    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 75, 25, 50, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPoolin  (None, 75, 12, 25, 256)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 75, 12, 25, 75)    172875    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 75, 12, 25, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPoolin  (None, 75, 6, 12, 75)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 75, 5400)          0         \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 75, 512)           11585536  \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 75, 512)           1574912   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 75, 29)            14877     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13644648 (52.05 MB)\n",
      "Trainable params: 13644648 (52.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lip_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[8.7288373e-07]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = tf.convert_to_tensor([[1, 2, 0, 0]], dtype=tf.int32)\n",
    "# labels = tf.one_hot(labels, 3, dtype=tf.int32)\n",
    "inputs = tf.convert_to_tensor([\n",
    "    [[0, 1, 0, 0],\n",
    "     [0, 0, 0, 1],\n",
    "     [0, 0, 1, 0]]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "input_lenght = tf.constant([[3]], dtype=tf.int32)\n",
    "label_length = tf.constant([[2]], dtype=tf.int32)\n",
    "\n",
    "loss_val = tf.keras.backend.ctc_batch_cost(\n",
    "    labels,\n",
    "    inputs,\n",
    "    input_length=input_lenght,\n",
    "    label_length=label_length\n",
    ")\n",
    "loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(labels, preds):\n",
    "    batch_size, seq_length, _ = preds.shape\n",
    "    # print(preds.shape)\n",
    "    label_length = tf.reduce_sum(tf.cast(tf.not_equal(labels, 0), tf.int32), axis=1, keepdims=True)\n",
    "    input_length = tf.ones((4, 1), dtype=tf.int32) * seq_length\n",
    "    \n",
    "    loss_val = tf.keras.backend.ctc_batch_cost(\n",
    "        labels, \n",
    "        preds,\n",
    "        input_length=input_length,\n",
    "        label_length=label_length\n",
    "    )\n",
    "    \n",
    "    return loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):           \n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip_net.compile(optimizer=\"adam\", loss=CTCLoss)\n",
    "schedule_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True) \n",
    "example_callback = ProduceExample(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/200 [..............................] - ETA: 10:25 - loss: 119.6530"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlip_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32md:\\Edu\\python_projects\\lips_reader\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lip_net.fit(train_dataset, validation_data=test_dataset, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.ctc_batch_cost()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
